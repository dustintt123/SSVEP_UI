{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as io\n",
    "import os\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Input, Flatten\n",
    "import keras.backend as K\n",
    "from keras.constraints import max_norm\n",
    "from keras.regularizers import l1_l2\n",
    "from keras.layers.core import Dense, Activation, Dropout, Permute, Reshape\n",
    "from keras.callbacks import Callback, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "def square(x):\n",
    "    return K.square(x)\n",
    "\n",
    "def log(x):\n",
    "    return K.log(K.clip(x, min_value = 1e-7, max_value = 10000))   \n",
    "\n",
    "def safe_log(x):\n",
    "    return K.log(x + 1e-7)\n",
    "\n",
    "def process_data(train, label, n_class=2, day_index=1, subject_index=1, shuffle=True):\n",
    "    train = np.squeeze(train[:,:,np.where(label[:,1]==day_index)])\n",
    "    train = np.transpose(train, axes=[2,0,1])\n",
    "    train = train.reshape(train.shape[0], 1, train.shape[1], train.shape[2])\n",
    "    \n",
    "    label = np.squeeze(label[np.where(label[:,1]==day_index),0])   \n",
    "    if n_class == 2:\n",
    "        label[np.where(label != subject_index)] = subject_index + 1\n",
    "        label = keras.utils.to_categorical(label-subject_index, n_class)\n",
    "    else:\n",
    "        label = keras.utils.to_categorical(label-1, n_class)\n",
    "        \n",
    "    if shuffle:\n",
    "        permutation = np.random.permutation(train.shape[0])\n",
    "        train = train[permutation,:,:]\n",
    "        label = label[permutation,:]\n",
    "        \n",
    "    return train, label "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Keras implementation of the Shallow Convolutional Network as described\n",
    "    in Schirrmeister et. al. (2017), arXiv 1703.0505\n",
    "    \n",
    "    Assumes the input is a 2-second EEG signal sampled at 128Hz. Note that in \n",
    "    the original paper, they do temporal convolutions of length 25 for EEG\n",
    "    data sampled at 250Hz. We instead use length 13 since the sampling rate is \n",
    "    roughly half of the 250Hz which the paper used. The pool_size and stride\n",
    "    in later layers is also approximately half of what is used in the paper.\n",
    "    \n",
    "                     ours        original paper\n",
    "    pool_size        1, 35       1, 75\n",
    "    strides          1, 7        1, 15\n",
    "    conv filters     1, 13       1, 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ShallowConvNet(input_shape, n_class=2, conv1_size=(1, 13), conv2_size=(9, 25), conv1_filter=5, conv2_filter=10):\n",
    "    dropout_rate = 0.5\n",
    "    \n",
    "    # start the model\n",
    "    input_EEG = Input(input_shape)\n",
    "    block1       = Conv2D(conv1_filter, conv1_size, kernel_constraint = max_norm(2.))(input_EEG)\n",
    "    block1       = Conv2D(conv2_filter, conv2_size, use_bias=True, kernel_constraint = max_norm(2.))(block1)\n",
    "    block1       = BatchNormalization(axis=1, epsilon=1e-05, momentum=0.1)(block1)\n",
    "    block1       = Activation(square)(block1)\n",
    "    block1       = AveragePooling2D(pool_size=(1, 30), strides=(1, 10))(block1)\n",
    "    block1       = Activation(safe_log)(block1)\n",
    "    block1       = Dropout(dropout_rate)(block1)\n",
    "    flatten      = Flatten()(block1)\n",
    "    dense        = Dense(n_class, kernel_constraint = max_norm(0.5))(flatten)\n",
    "    softmax      = Activation('softmax')(dense)\n",
    "    \n",
    "    return Model(inputs=input_EEG, outputs=softmax)\n",
    "\n",
    "class AccLossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.acc = []\n",
    "        self.loss = []\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.acc.append([logs.get('acc'), logs.get('val_acc')])\n",
    "        self.loss.append([logs.get('loss'), logs.get('val_loss')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datapath = '/Users/dustintt123/SSVEP_CNN/SSVEP_Data/'\n",
    "SSVEP_l = io.loadmat(datapath+'SSVEP_l.mat')['SSVEP_l']\n",
    "SSVEP_h = io.loadmat(datapath+'SSVEP_h.mat')['SSVEP_h']\n",
    "SSVEP_label = io.loadmat(datapath+'SSVEP_label.mat')['label'] # i_subj, i_session, i_stim, i_trial\n",
    "\n",
    "# binary one-vs-all classification\n",
    "batch_size = 100\n",
    "n_epoch = 150\n",
    "isEarlyStopping = False\n",
    "n_patience = 8\n",
    "\n",
    "history_list = []\n",
    "score_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1440 samples, validate on 480 samples\n",
      "Epoch 1/150\n",
      "1440/1440 [==============================] - 10s 7ms/step - loss: 0.6665 - acc: 0.7340 - val_loss: 0.4127 - val_acc: 0.8521\n",
      "Epoch 2/150\n",
      "1440/1440 [==============================] - 5s 4ms/step - loss: 0.4298 - acc: 0.8167 - val_loss: 0.3791 - val_acc: 0.8583\n",
      "Epoch 3/150\n",
      "1440/1440 [==============================] - 5s 4ms/step - loss: 0.3843 - acc: 0.8535 - val_loss: 0.3019 - val_acc: 0.8667\n",
      "Epoch 4/150\n",
      "1440/1440 [==============================] - 5s 4ms/step - loss: 0.3143 - acc: 0.8632 - val_loss: 0.2669 - val_acc: 0.8833\n",
      "Epoch 5/150\n",
      "1440/1440 [==============================] - 5s 4ms/step - loss: 0.2940 - acc: 0.8778 - val_loss: 0.2219 - val_acc: 0.8958\n",
      "Epoch 6/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2347 - acc: 0.9042 - val_loss: 0.2286 - val_acc: 0.8937\n",
      "Epoch 7/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2233 - acc: 0.9062 - val_loss: 0.1921 - val_acc: 0.9292\n",
      "Epoch 8/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2130 - acc: 0.9153 - val_loss: 0.1816 - val_acc: 0.9292\n",
      "Epoch 9/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1903 - acc: 0.9292 - val_loss: 0.1486 - val_acc: 0.9396\n",
      "Epoch 10/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1665 - acc: 0.9354 - val_loss: 0.1364 - val_acc: 0.9417\n",
      "Epoch 11/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1734 - acc: 0.9333 - val_loss: 0.1561 - val_acc: 0.9333\n",
      "Epoch 12/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1637 - acc: 0.9375 - val_loss: 0.1536 - val_acc: 0.9208\n",
      "Epoch 13/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1899 - acc: 0.9333 - val_loss: 0.1543 - val_acc: 0.9396\n",
      "Epoch 14/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1523 - acc: 0.9451 - val_loss: 0.1208 - val_acc: 0.9542\n",
      "Epoch 15/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1315 - acc: 0.9500 - val_loss: 0.1137 - val_acc: 0.9562\n",
      "Epoch 16/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1234 - acc: 0.9556 - val_loss: 0.1100 - val_acc: 0.9521\n",
      "Epoch 17/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1239 - acc: 0.9632 - val_loss: 0.0938 - val_acc: 0.9604\n",
      "Epoch 18/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1106 - acc: 0.9681 - val_loss: 0.0810 - val_acc: 0.9688\n",
      "Epoch 19/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1065 - acc: 0.9688 - val_loss: 0.0597 - val_acc: 0.9771\n",
      "Epoch 20/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0798 - acc: 0.9757 - val_loss: 0.0924 - val_acc: 0.9625\n",
      "Epoch 21/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0948 - acc: 0.9694 - val_loss: 0.0600 - val_acc: 0.9833\n",
      "Epoch 22/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0698 - acc: 0.9792 - val_loss: 0.0660 - val_acc: 0.9771\n",
      "Epoch 23/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0742 - acc: 0.9785 - val_loss: 0.0608 - val_acc: 0.9771\n",
      "Epoch 24/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0713 - acc: 0.9750 - val_loss: 0.0537 - val_acc: 0.9771\n",
      "Epoch 25/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0635 - acc: 0.9771 - val_loss: 0.0448 - val_acc: 0.9875\n",
      "Epoch 26/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0503 - acc: 0.9854 - val_loss: 0.0366 - val_acc: 0.9938\n",
      "Epoch 27/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0634 - acc: 0.9819 - val_loss: 0.0304 - val_acc: 0.9958\n",
      "Epoch 28/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0578 - acc: 0.9847 - val_loss: 0.0477 - val_acc: 0.9771\n",
      "Epoch 29/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0504 - acc: 0.9847 - val_loss: 0.0509 - val_acc: 0.9813\n",
      "Epoch 30/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0506 - acc: 0.9833 - val_loss: 0.0324 - val_acc: 0.9958\n",
      "Epoch 31/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0449 - acc: 0.9861 - val_loss: 0.0426 - val_acc: 0.9896\n",
      "Epoch 32/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0477 - acc: 0.9840 - val_loss: 0.0332 - val_acc: 0.9896\n",
      "Epoch 33/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0498 - acc: 0.9868 - val_loss: 0.0470 - val_acc: 0.9854\n",
      "Epoch 34/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0607 - acc: 0.9847 - val_loss: 0.0419 - val_acc: 0.9854\n",
      "Epoch 35/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0485 - acc: 0.9882 - val_loss: 0.0366 - val_acc: 0.9917\n",
      "Epoch 00035: early stopping\n",
      "Train on 1440 samples, validate on 480 samples\n",
      "Epoch 1/150\n",
      "1440/1440 [==============================] - 10s 7ms/step - loss: 0.4906 - acc: 0.7889 - val_loss: 0.4092 - val_acc: 0.8208\n",
      "Epoch 2/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.3568 - acc: 0.8514 - val_loss: 0.3409 - val_acc: 0.8521\n",
      "Epoch 3/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.3014 - acc: 0.8806 - val_loss: 0.3349 - val_acc: 0.8542\n",
      "Epoch 4/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2701 - acc: 0.8931 - val_loss: 0.3474 - val_acc: 0.8479\n",
      "Epoch 5/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2546 - acc: 0.9007 - val_loss: 0.2946 - val_acc: 0.8687\n",
      "Epoch 6/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2244 - acc: 0.9167 - val_loss: 0.2850 - val_acc: 0.8750\n",
      "Epoch 7/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2133 - acc: 0.9167 - val_loss: 0.2582 - val_acc: 0.8833\n",
      "Epoch 8/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2083 - acc: 0.9188 - val_loss: 0.2443 - val_acc: 0.9000\n",
      "Epoch 9/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2048 - acc: 0.9194 - val_loss: 0.2695 - val_acc: 0.8937\n",
      "Epoch 10/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2004 - acc: 0.9236 - val_loss: 0.2391 - val_acc: 0.9104\n",
      "Epoch 11/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1959 - acc: 0.9208 - val_loss: 0.2426 - val_acc: 0.9063\n",
      "Epoch 12/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1638 - acc: 0.9382 - val_loss: 0.2515 - val_acc: 0.9083\n",
      "Epoch 13/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1808 - acc: 0.9285 - val_loss: 0.2402 - val_acc: 0.9083\n",
      "Epoch 14/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1764 - acc: 0.9326 - val_loss: 0.2248 - val_acc: 0.9042\n",
      "Epoch 15/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1615 - acc: 0.9313 - val_loss: 0.2260 - val_acc: 0.9042\n",
      "Epoch 16/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1342 - acc: 0.9465 - val_loss: 0.1450 - val_acc: 0.9438\n",
      "Epoch 17/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1208 - acc: 0.9583 - val_loss: 0.1358 - val_acc: 0.9458\n",
      "Epoch 18/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1261 - acc: 0.9549 - val_loss: 0.1971 - val_acc: 0.9354\n",
      "Epoch 19/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1194 - acc: 0.9486 - val_loss: 0.1265 - val_acc: 0.9562\n",
      "Epoch 20/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1074 - acc: 0.9556 - val_loss: 0.1602 - val_acc: 0.9250\n",
      "Epoch 21/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1188 - acc: 0.9549 - val_loss: 0.1813 - val_acc: 0.9167\n",
      "Epoch 22/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1171 - acc: 0.9528 - val_loss: 0.1659 - val_acc: 0.9437\n",
      "Epoch 23/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0947 - acc: 0.9667 - val_loss: 0.0961 - val_acc: 0.9688\n",
      "Epoch 24/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0914 - acc: 0.9660 - val_loss: 0.0972 - val_acc: 0.9667\n",
      "Epoch 25/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0830 - acc: 0.9625 - val_loss: 0.1350 - val_acc: 0.9417\n",
      "Epoch 26/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0996 - acc: 0.9604 - val_loss: 0.1246 - val_acc: 0.9542\n",
      "Epoch 27/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0933 - acc: 0.9667 - val_loss: 0.1258 - val_acc: 0.9437\n",
      "Epoch 28/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1066 - acc: 0.9569 - val_loss: 0.0792 - val_acc: 0.9771\n",
      "Epoch 29/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1017 - acc: 0.9618 - val_loss: 0.1036 - val_acc: 0.9562\n",
      "Epoch 30/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0737 - acc: 0.9736 - val_loss: 0.0955 - val_acc: 0.9667\n",
      "Epoch 31/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0770 - acc: 0.9736 - val_loss: 0.0708 - val_acc: 0.9729\n",
      "Epoch 32/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0717 - acc: 0.9757 - val_loss: 0.1442 - val_acc: 0.9375\n",
      "Epoch 33/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0684 - acc: 0.9715 - val_loss: 0.0735 - val_acc: 0.9708\n",
      "Epoch 34/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0791 - acc: 0.9708 - val_loss: 0.0844 - val_acc: 0.9604\n",
      "Epoch 35/150\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0669 - acc: 0.9771 - val_loss: 0.0823 - val_acc: 0.9729\n",
      "Epoch 36/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0563 - acc: 0.9757 - val_loss: 0.0492 - val_acc: 0.9833\n",
      "Epoch 37/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0703 - acc: 0.9743 - val_loss: 0.1228 - val_acc: 0.9542\n",
      "Epoch 38/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0449 - acc: 0.9861 - val_loss: 0.0974 - val_acc: 0.9646\n",
      "Epoch 39/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0625 - acc: 0.9785 - val_loss: 0.0774 - val_acc: 0.9771\n",
      "Epoch 40/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0535 - acc: 0.9847 - val_loss: 0.0592 - val_acc: 0.9792\n",
      "Epoch 41/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0415 - acc: 0.9868 - val_loss: 0.0677 - val_acc: 0.9729\n",
      "Epoch 42/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0477 - acc: 0.9819 - val_loss: 0.0466 - val_acc: 0.9792\n",
      "Epoch 43/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0355 - acc: 0.9882 - val_loss: 0.0559 - val_acc: 0.9833\n",
      "Epoch 44/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0378 - acc: 0.9896 - val_loss: 0.0436 - val_acc: 0.9833\n",
      "Epoch 00044: early stopping\n",
      "Train on 1440 samples, validate on 480 samples\n",
      "Epoch 1/150\n",
      "1440/1440 [==============================] - 10s 7ms/step - loss: 0.7777 - acc: 0.6472 - val_loss: 0.4385 - val_acc: 0.8146\n",
      "Epoch 2/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.6072 - acc: 0.7250 - val_loss: 0.4069 - val_acc: 0.8417\n",
      "Epoch 3/150\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.5522 - acc: 0.7687 - val_loss: 0.3642 - val_acc: 0.8646\n",
      "Epoch 4/150\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.5001 - acc: 0.7972 - val_loss: 0.3496 - val_acc: 0.8688\n",
      "Epoch 5/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.4519 - acc: 0.8160 - val_loss: 0.3242 - val_acc: 0.8812\n",
      "Epoch 6/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.4289 - acc: 0.8160 - val_loss: 0.3426 - val_acc: 0.8646\n",
      "Epoch 7/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.4031 - acc: 0.8340 - val_loss: 0.3265 - val_acc: 0.8729\n",
      "Epoch 8/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.3844 - acc: 0.8389 - val_loss: 0.3437 - val_acc: 0.8792\n",
      "Epoch 9/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.3749 - acc: 0.8493 - val_loss: 0.3078 - val_acc: 0.8854\n",
      "Epoch 10/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.3519 - acc: 0.8604 - val_loss: 0.2749 - val_acc: 0.8937\n",
      "Epoch 11/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.3309 - acc: 0.8653 - val_loss: 0.2439 - val_acc: 0.9042\n",
      "Epoch 12/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.3084 - acc: 0.8722 - val_loss: 0.2483 - val_acc: 0.9021\n",
      "Epoch 13/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2875 - acc: 0.8799 - val_loss: 0.2401 - val_acc: 0.9208\n",
      "Epoch 14/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2936 - acc: 0.8847 - val_loss: 0.2433 - val_acc: 0.9167\n",
      "Epoch 15/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2695 - acc: 0.8854 - val_loss: 0.2396 - val_acc: 0.9083\n",
      "Epoch 16/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2441 - acc: 0.8958 - val_loss: 0.2164 - val_acc: 0.9167\n",
      "Epoch 17/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2139 - acc: 0.9090 - val_loss: 0.1916 - val_acc: 0.9271\n",
      "Epoch 18/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1937 - acc: 0.9222 - val_loss: 0.1353 - val_acc: 0.9521\n",
      "Epoch 19/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1747 - acc: 0.9285 - val_loss: 0.1612 - val_acc: 0.9292\n",
      "Epoch 20/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1698 - acc: 0.9375 - val_loss: 0.1219 - val_acc: 0.9604\n",
      "Epoch 21/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1636 - acc: 0.9396 - val_loss: 0.1290 - val_acc: 0.9396\n",
      "Epoch 22/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1521 - acc: 0.9458 - val_loss: 0.1171 - val_acc: 0.9542\n",
      "Epoch 23/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1442 - acc: 0.9410 - val_loss: 0.1081 - val_acc: 0.9646\n",
      "Epoch 24/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1271 - acc: 0.9528 - val_loss: 0.1083 - val_acc: 0.9521\n",
      "Epoch 25/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1148 - acc: 0.9563 - val_loss: 0.0692 - val_acc: 0.9813\n",
      "Epoch 26/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0853 - acc: 0.9653 - val_loss: 0.0639 - val_acc: 0.9771\n",
      "Epoch 27/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0954 - acc: 0.9694 - val_loss: 0.0578 - val_acc: 0.9813\n",
      "Epoch 28/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0943 - acc: 0.9646 - val_loss: 0.0624 - val_acc: 0.9833\n",
      "Epoch 29/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0756 - acc: 0.9729 - val_loss: 0.0741 - val_acc: 0.9792\n",
      "Epoch 30/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0784 - acc: 0.9701 - val_loss: 0.0514 - val_acc: 0.9854\n",
      "Epoch 31/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0564 - acc: 0.9819 - val_loss: 0.0389 - val_acc: 0.9917\n",
      "Epoch 32/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0539 - acc: 0.9799 - val_loss: 0.0399 - val_acc: 0.9896\n",
      "Epoch 33/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0576 - acc: 0.9813 - val_loss: 0.0375 - val_acc: 0.9938\n",
      "Epoch 34/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0542 - acc: 0.9806 - val_loss: 0.0290 - val_acc: 0.9938\n",
      "Epoch 35/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0527 - acc: 0.9833 - val_loss: 0.0346 - val_acc: 0.9938\n",
      "Epoch 36/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0494 - acc: 0.9806 - val_loss: 0.0305 - val_acc: 0.9958\n",
      "Epoch 37/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0337 - acc: 0.9882 - val_loss: 0.0262 - val_acc: 0.9938\n",
      "Epoch 38/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0447 - acc: 0.9875 - val_loss: 0.0465 - val_acc: 0.9833\n",
      "Epoch 39/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0464 - acc: 0.9854 - val_loss: 0.0318 - val_acc: 0.9938\n",
      "Epoch 40/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0497 - acc: 0.9833 - val_loss: 0.0464 - val_acc: 0.9833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0458 - acc: 0.9854 - val_loss: 0.0286 - val_acc: 0.9958\n",
      "Epoch 42/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0638 - acc: 0.9806 - val_loss: 0.0429 - val_acc: 0.9917\n",
      "Epoch 43/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0503 - acc: 0.9861 - val_loss: 0.0323 - val_acc: 0.9958\n",
      "Epoch 44/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0386 - acc: 0.9896 - val_loss: 0.0247 - val_acc: 0.9958\n",
      "Epoch 00044: early stopping\n",
      "Train on 1440 samples, validate on 480 samples\n",
      "Epoch 1/150\n",
      "1440/1440 [==============================] - 10s 7ms/step - loss: 0.4411 - acc: 0.8319 - val_loss: 0.4181 - val_acc: 0.8479\n",
      "Epoch 2/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.3266 - acc: 0.8840 - val_loss: 0.4350 - val_acc: 0.8604\n",
      "Epoch 3/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.3058 - acc: 0.8806 - val_loss: 0.3841 - val_acc: 0.8583\n",
      "Epoch 4/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2658 - acc: 0.9035 - val_loss: 0.3494 - val_acc: 0.8625\n",
      "Epoch 5/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2285 - acc: 0.9174 - val_loss: 0.3331 - val_acc: 0.8750\n",
      "Epoch 6/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2340 - acc: 0.9118 - val_loss: 0.3274 - val_acc: 0.8729\n",
      "Epoch 7/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2022 - acc: 0.9187 - val_loss: 0.2447 - val_acc: 0.9104\n",
      "Epoch 8/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1788 - acc: 0.9326 - val_loss: 0.2540 - val_acc: 0.9000\n",
      "Epoch 9/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1792 - acc: 0.9271 - val_loss: 0.3132 - val_acc: 0.8833\n",
      "Epoch 10/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1716 - acc: 0.9306 - val_loss: 0.2561 - val_acc: 0.8958\n",
      "Epoch 11/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1630 - acc: 0.9313 - val_loss: 0.1929 - val_acc: 0.9271\n",
      "Epoch 12/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1198 - acc: 0.9576 - val_loss: 0.1596 - val_acc: 0.9417\n",
      "Epoch 13/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1262 - acc: 0.9535 - val_loss: 0.1289 - val_acc: 0.9479\n",
      "Epoch 14/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1183 - acc: 0.9542 - val_loss: 0.1315 - val_acc: 0.9521\n",
      "Epoch 15/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0983 - acc: 0.9597 - val_loss: 0.1378 - val_acc: 0.9521\n",
      "Epoch 16/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1097 - acc: 0.9576 - val_loss: 0.1437 - val_acc: 0.9333\n",
      "Epoch 17/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0876 - acc: 0.9674 - val_loss: 0.1106 - val_acc: 0.9583\n",
      "Epoch 18/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0949 - acc: 0.9660 - val_loss: 0.1524 - val_acc: 0.9437\n",
      "Epoch 19/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0866 - acc: 0.9646 - val_loss: 0.1017 - val_acc: 0.9542\n",
      "Epoch 20/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0725 - acc: 0.9771 - val_loss: 0.0856 - val_acc: 0.9708\n",
      "Epoch 21/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0564 - acc: 0.9826 - val_loss: 0.0625 - val_acc: 0.9792\n",
      "Epoch 22/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0469 - acc: 0.9861 - val_loss: 0.0538 - val_acc: 0.9813\n",
      "Epoch 23/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0572 - acc: 0.9778 - val_loss: 0.0767 - val_acc: 0.9729\n",
      "Epoch 24/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0499 - acc: 0.9840 - val_loss: 0.0460 - val_acc: 0.9854\n",
      "Epoch 25/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0414 - acc: 0.9882 - val_loss: 0.0626 - val_acc: 0.9708\n",
      "Epoch 26/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0363 - acc: 0.9882 - val_loss: 0.0494 - val_acc: 0.9813\n",
      "Epoch 27/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0364 - acc: 0.9896 - val_loss: 0.0454 - val_acc: 0.9813\n",
      "Epoch 28/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0330 - acc: 0.9889 - val_loss: 0.0584 - val_acc: 0.9792\n",
      "Epoch 29/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0198 - acc: 0.9972 - val_loss: 0.0634 - val_acc: 0.9750\n",
      "Epoch 30/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0244 - acc: 0.9931 - val_loss: 0.0655 - val_acc: 0.9750\n",
      "Epoch 31/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0266 - acc: 0.9924 - val_loss: 0.0459 - val_acc: 0.9813\n",
      "Epoch 32/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0287 - acc: 0.9917 - val_loss: 0.0589 - val_acc: 0.9792\n",
      "Epoch 00032: early stopping\n",
      "Train on 1440 samples, validate on 480 samples\n",
      "Epoch 1/150\n",
      "1440/1440 [==============================] - 10s 7ms/step - loss: 0.6632 - acc: 0.7229 - val_loss: 0.4737 - val_acc: 0.8271\n",
      "Epoch 2/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.4796 - acc: 0.8236 - val_loss: 0.4543 - val_acc: 0.8604\n",
      "Epoch 3/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.4508 - acc: 0.8403 - val_loss: 0.4100 - val_acc: 0.8604\n",
      "Epoch 4/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.4259 - acc: 0.8410 - val_loss: 0.3978 - val_acc: 0.8688\n",
      "Epoch 5/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.4123 - acc: 0.8604 - val_loss: 0.3637 - val_acc: 0.8750\n",
      "Epoch 6/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.3912 - acc: 0.8479 - val_loss: 0.3615 - val_acc: 0.8646\n",
      "Epoch 7/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.3735 - acc: 0.8618 - val_loss: 0.3402 - val_acc: 0.8646\n",
      "Epoch 8/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.3560 - acc: 0.8694 - val_loss: 0.3129 - val_acc: 0.8750\n",
      "Epoch 9/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.3323 - acc: 0.8646 - val_loss: 0.2925 - val_acc: 0.8729\n",
      "Epoch 10/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.3145 - acc: 0.8743 - val_loss: 0.2576 - val_acc: 0.8750\n",
      "Epoch 11/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2833 - acc: 0.8833 - val_loss: 0.2668 - val_acc: 0.8937\n",
      "Epoch 12/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2726 - acc: 0.8903 - val_loss: 0.2385 - val_acc: 0.9104\n",
      "Epoch 13/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2652 - acc: 0.8931 - val_loss: 0.2271 - val_acc: 0.8875\n",
      "Epoch 14/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2438 - acc: 0.9035 - val_loss: 0.2082 - val_acc: 0.9146\n",
      "Epoch 15/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2019 - acc: 0.9160 - val_loss: 0.1763 - val_acc: 0.9313\n",
      "Epoch 16/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1828 - acc: 0.9292 - val_loss: 0.1484 - val_acc: 0.9417\n",
      "Epoch 17/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1866 - acc: 0.9201 - val_loss: 0.1581 - val_acc: 0.9292\n",
      "Epoch 18/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1935 - acc: 0.9292 - val_loss: 0.1768 - val_acc: 0.9250\n",
      "Epoch 19/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1825 - acc: 0.9243 - val_loss: 0.1378 - val_acc: 0.9521\n",
      "Epoch 20/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1718 - acc: 0.9375 - val_loss: 0.1527 - val_acc: 0.9500\n",
      "Epoch 21/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1664 - acc: 0.9340 - val_loss: 0.1413 - val_acc: 0.9354\n",
      "Epoch 22/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1452 - acc: 0.9431 - val_loss: 0.1213 - val_acc: 0.9542\n",
      "Epoch 23/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1406 - acc: 0.9486 - val_loss: 0.1223 - val_acc: 0.9437\n",
      "Epoch 24/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1253 - acc: 0.9590 - val_loss: 0.1316 - val_acc: 0.9438\n",
      "Epoch 25/150\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.1233 - acc: 0.9549 - val_loss: 0.1114 - val_acc: 0.9396\n",
      "Epoch 26/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1068 - acc: 0.9590 - val_loss: 0.0982 - val_acc: 0.9583\n",
      "Epoch 27/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1076 - acc: 0.9646 - val_loss: 0.1071 - val_acc: 0.9667\n",
      "Epoch 28/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1192 - acc: 0.9514 - val_loss: 0.1083 - val_acc: 0.9458\n",
      "Epoch 29/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1192 - acc: 0.9542 - val_loss: 0.0977 - val_acc: 0.9688\n",
      "Epoch 30/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1010 - acc: 0.9618 - val_loss: 0.0884 - val_acc: 0.9729\n",
      "Epoch 31/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1010 - acc: 0.9639 - val_loss: 0.1021 - val_acc: 0.9604\n",
      "Epoch 32/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1086 - acc: 0.9549 - val_loss: 0.1080 - val_acc: 0.9583\n",
      "Epoch 33/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0974 - acc: 0.9653 - val_loss: 0.0983 - val_acc: 0.9542\n",
      "Epoch 34/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0817 - acc: 0.9743 - val_loss: 0.0897 - val_acc: 0.9625\n",
      "Epoch 35/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0896 - acc: 0.9688 - val_loss: 0.0770 - val_acc: 0.9729\n",
      "Epoch 36/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0856 - acc: 0.9694 - val_loss: 0.0796 - val_acc: 0.9646\n",
      "Epoch 37/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0870 - acc: 0.9639 - val_loss: 0.0752 - val_acc: 0.9750\n",
      "Epoch 38/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0866 - acc: 0.9646 - val_loss: 0.0873 - val_acc: 0.9625\n",
      "Epoch 39/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0763 - acc: 0.9715 - val_loss: 0.0692 - val_acc: 0.9729\n",
      "Epoch 40/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0744 - acc: 0.9778 - val_loss: 0.0693 - val_acc: 0.9667\n",
      "Epoch 41/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0819 - acc: 0.9722 - val_loss: 0.0734 - val_acc: 0.9729\n",
      "Epoch 42/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0787 - acc: 0.9743 - val_loss: 0.0699 - val_acc: 0.9667\n",
      "Epoch 43/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0750 - acc: 0.9694 - val_loss: 0.0804 - val_acc: 0.9625\n",
      "Epoch 44/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0784 - acc: 0.9701 - val_loss: 0.0700 - val_acc: 0.9729\n",
      "Epoch 45/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0700 - acc: 0.9764 - val_loss: 0.0666 - val_acc: 0.9771\n",
      "Epoch 46/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0843 - acc: 0.9694 - val_loss: 0.0790 - val_acc: 0.9583\n",
      "Epoch 47/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0731 - acc: 0.9715 - val_loss: 0.0701 - val_acc: 0.9771\n",
      "Epoch 48/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0649 - acc: 0.9785 - val_loss: 0.0730 - val_acc: 0.9646\n",
      "Epoch 49/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0639 - acc: 0.9764 - val_loss: 0.0854 - val_acc: 0.9646\n",
      "Epoch 50/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0611 - acc: 0.9833 - val_loss: 0.0701 - val_acc: 0.9771\n",
      "Epoch 51/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0771 - acc: 0.9681 - val_loss: 0.0536 - val_acc: 0.9813\n",
      "Epoch 52/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0736 - acc: 0.9729 - val_loss: 0.0656 - val_acc: 0.9792\n",
      "Epoch 53/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0656 - acc: 0.9771 - val_loss: 0.0994 - val_acc: 0.9667\n",
      "Epoch 54/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0610 - acc: 0.9799 - val_loss: 0.0619 - val_acc: 0.9750\n",
      "Epoch 55/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0563 - acc: 0.9764 - val_loss: 0.0561 - val_acc: 0.9854\n",
      "Epoch 56/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0612 - acc: 0.9764 - val_loss: 0.0630 - val_acc: 0.9729\n",
      "Epoch 57/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0521 - acc: 0.9806 - val_loss: 0.0533 - val_acc: 0.9792\n",
      "Epoch 58/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0559 - acc: 0.9757 - val_loss: 0.0595 - val_acc: 0.9771\n",
      "Epoch 59/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0639 - acc: 0.9778 - val_loss: 0.0579 - val_acc: 0.9854\n",
      "Epoch 60/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0561 - acc: 0.9806 - val_loss: 0.0638 - val_acc: 0.9813\n",
      "Epoch 61/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0509 - acc: 0.9813 - val_loss: 0.0505 - val_acc: 0.9750\n",
      "Epoch 62/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0567 - acc: 0.9771 - val_loss: 0.0699 - val_acc: 0.9750\n",
      "Epoch 63/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0588 - acc: 0.9799 - val_loss: 0.0658 - val_acc: 0.9854\n",
      "Epoch 00063: early stopping\n",
      "Train on 1440 samples, validate on 480 samples\n",
      "Epoch 1/150\n",
      "1440/1440 [==============================] - 10s 7ms/step - loss: 0.4751 - acc: 0.8062 - val_loss: 0.3545 - val_acc: 0.8792\n",
      "Epoch 2/150\n",
      "1440/1440 [==============================] - 5s 4ms/step - loss: 0.3621 - acc: 0.8507 - val_loss: 0.2924 - val_acc: 0.8917\n",
      "Epoch 3/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2981 - acc: 0.8868 - val_loss: 0.2409 - val_acc: 0.9000\n",
      "Epoch 4/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2811 - acc: 0.8847 - val_loss: 0.2717 - val_acc: 0.9042\n",
      "Epoch 5/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2712 - acc: 0.8917 - val_loss: 0.2168 - val_acc: 0.9083\n",
      "Epoch 6/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2311 - acc: 0.9132 - val_loss: 0.2091 - val_acc: 0.9229\n",
      "Epoch 7/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2166 - acc: 0.9236 - val_loss: 0.2166 - val_acc: 0.9042\n",
      "Epoch 8/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2277 - acc: 0.9097 - val_loss: 0.1796 - val_acc: 0.9271\n",
      "Epoch 9/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1850 - acc: 0.9312 - val_loss: 0.1729 - val_acc: 0.9417\n",
      "Epoch 10/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2012 - acc: 0.9208 - val_loss: 0.1844 - val_acc: 0.9333\n",
      "Epoch 11/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1727 - acc: 0.9306 - val_loss: 0.1621 - val_acc: 0.9438\n",
      "Epoch 12/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1620 - acc: 0.9403 - val_loss: 0.1516 - val_acc: 0.9417\n",
      "Epoch 13/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1749 - acc: 0.9292 - val_loss: 0.1497 - val_acc: 0.9333\n",
      "Epoch 14/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1558 - acc: 0.9403 - val_loss: 0.1429 - val_acc: 0.9417\n",
      "Epoch 15/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1668 - acc: 0.9340 - val_loss: 0.1388 - val_acc: 0.9500\n",
      "Epoch 16/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1561 - acc: 0.9333 - val_loss: 0.1252 - val_acc: 0.9500\n",
      "Epoch 17/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1391 - acc: 0.9431 - val_loss: 0.1342 - val_acc: 0.9479\n",
      "Epoch 18/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1489 - acc: 0.9479 - val_loss: 0.1542 - val_acc: 0.9458\n",
      "Epoch 19/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1438 - acc: 0.9431 - val_loss: 0.1611 - val_acc: 0.9417\n",
      "Epoch 20/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1408 - acc: 0.9500 - val_loss: 0.1200 - val_acc: 0.9542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1266 - acc: 0.9604 - val_loss: 0.1149 - val_acc: 0.9604\n",
      "Epoch 22/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1253 - acc: 0.9486 - val_loss: 0.1289 - val_acc: 0.9542\n",
      "Epoch 23/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1173 - acc: 0.9549 - val_loss: 0.1210 - val_acc: 0.9500\n",
      "Epoch 24/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1295 - acc: 0.9500 - val_loss: 0.1094 - val_acc: 0.9604\n",
      "Epoch 25/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1220 - acc: 0.9528 - val_loss: 0.1147 - val_acc: 0.9583\n",
      "Epoch 26/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1271 - acc: 0.9556 - val_loss: 0.1203 - val_acc: 0.9542\n",
      "Epoch 27/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1186 - acc: 0.9556 - val_loss: 0.1025 - val_acc: 0.9604\n",
      "Epoch 28/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1075 - acc: 0.9576 - val_loss: 0.1066 - val_acc: 0.9563\n",
      "Epoch 29/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0938 - acc: 0.9694 - val_loss: 0.0928 - val_acc: 0.9708\n",
      "Epoch 30/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0969 - acc: 0.9611 - val_loss: 0.0985 - val_acc: 0.9625\n",
      "Epoch 31/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1093 - acc: 0.9611 - val_loss: 0.1094 - val_acc: 0.9583\n",
      "Epoch 32/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0961 - acc: 0.9660 - val_loss: 0.1032 - val_acc: 0.9542\n",
      "Epoch 33/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0946 - acc: 0.9660 - val_loss: 0.0989 - val_acc: 0.9604\n",
      "Epoch 34/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0960 - acc: 0.9604 - val_loss: 0.1040 - val_acc: 0.9646\n",
      "Epoch 35/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1001 - acc: 0.9625 - val_loss: 0.1121 - val_acc: 0.9563\n",
      "Epoch 36/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0885 - acc: 0.9701 - val_loss: 0.0991 - val_acc: 0.9625\n",
      "Epoch 37/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0843 - acc: 0.9688 - val_loss: 0.0842 - val_acc: 0.9667\n",
      "Epoch 00037: early stopping\n",
      "Train on 1440 samples, validate on 480 samples\n",
      "Epoch 1/150\n",
      "1440/1440 [==============================] - 10s 7ms/step - loss: 0.7301 - acc: 0.7028 - val_loss: 0.6079 - val_acc: 0.7875\n",
      "Epoch 2/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.4846 - acc: 0.8028 - val_loss: 0.4452 - val_acc: 0.8083\n",
      "Epoch 3/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.4458 - acc: 0.8167 - val_loss: 0.4119 - val_acc: 0.8333\n",
      "Epoch 4/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.3976 - acc: 0.8486 - val_loss: 0.3853 - val_acc: 0.8479\n",
      "Epoch 5/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.3620 - acc: 0.8535 - val_loss: 0.3561 - val_acc: 0.8563\n",
      "Epoch 6/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.3584 - acc: 0.8563 - val_loss: 0.3689 - val_acc: 0.8583\n",
      "Epoch 7/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.3387 - acc: 0.8688 - val_loss: 0.4868 - val_acc: 0.8542\n",
      "Epoch 8/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.3067 - acc: 0.8743 - val_loss: 0.3266 - val_acc: 0.8646\n",
      "Epoch 9/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.3047 - acc: 0.8722 - val_loss: 0.3626 - val_acc: 0.8625\n",
      "Epoch 10/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2909 - acc: 0.8833 - val_loss: 0.3299 - val_acc: 0.8667\n",
      "Epoch 11/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2716 - acc: 0.8840 - val_loss: 0.3141 - val_acc: 0.8687\n",
      "Epoch 12/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2633 - acc: 0.8861 - val_loss: 0.3047 - val_acc: 0.8708\n",
      "Epoch 13/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2568 - acc: 0.8958 - val_loss: 0.3103 - val_acc: 0.8771\n",
      "Epoch 14/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2627 - acc: 0.8958 - val_loss: 0.3095 - val_acc: 0.8687\n",
      "Epoch 15/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2357 - acc: 0.9035 - val_loss: 0.3023 - val_acc: 0.8750\n",
      "Epoch 16/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2393 - acc: 0.8951 - val_loss: 0.3127 - val_acc: 0.8667\n",
      "Epoch 17/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2645 - acc: 0.8868 - val_loss: 0.2775 - val_acc: 0.8771\n",
      "Epoch 18/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2300 - acc: 0.9090 - val_loss: 0.3157 - val_acc: 0.8708\n",
      "Epoch 19/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2290 - acc: 0.9000 - val_loss: 0.2891 - val_acc: 0.8750\n",
      "Epoch 20/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2346 - acc: 0.9049 - val_loss: 0.3046 - val_acc: 0.8708\n",
      "Epoch 21/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2309 - acc: 0.9083 - val_loss: 0.2728 - val_acc: 0.8750\n",
      "Epoch 00021: early stopping\n",
      "Train on 1440 samples, validate on 480 samples\n",
      "Epoch 1/150\n",
      "1440/1440 [==============================] - 10s 7ms/step - loss: 0.5810 - acc: 0.7451 - val_loss: 0.4048 - val_acc: 0.8417\n",
      "Epoch 2/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.4371 - acc: 0.8375 - val_loss: 0.3465 - val_acc: 0.8750\n",
      "Epoch 3/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.3990 - acc: 0.8431 - val_loss: 0.3302 - val_acc: 0.8813\n",
      "Epoch 4/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.3733 - acc: 0.8618 - val_loss: 0.2988 - val_acc: 0.8938\n",
      "Epoch 5/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.3528 - acc: 0.8708 - val_loss: 0.3066 - val_acc: 0.8875\n",
      "Epoch 6/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.3207 - acc: 0.8778 - val_loss: 0.2973 - val_acc: 0.8917\n",
      "Epoch 7/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.3092 - acc: 0.8840 - val_loss: 0.2910 - val_acc: 0.8917\n",
      "Epoch 8/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2945 - acc: 0.8896 - val_loss: 0.2892 - val_acc: 0.8938\n",
      "Epoch 9/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2818 - acc: 0.8813 - val_loss: 0.2894 - val_acc: 0.8854\n",
      "Epoch 10/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2779 - acc: 0.8868 - val_loss: 0.2768 - val_acc: 0.8833\n",
      "Epoch 11/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2593 - acc: 0.9049 - val_loss: 0.2626 - val_acc: 0.8917\n",
      "Epoch 12/150\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2422 - acc: 0.9014 - val_loss: 0.2648 - val_acc: 0.8812\n",
      "Epoch 00012: early stopping\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    subject = 7\n",
    "    train_day = 1\n",
    "\n",
    "    x_train, y_train = process_data(SSVEP_l, SSVEP_label, n_class=2, day_index=train_day, subject_index=subject)\n",
    "    n_trial, n_height, n_channel, n_timestamp = x_train.shape\n",
    "\n",
    "    # Setup model\n",
    "    model = ShallowConvNet(x_train.shape[1:])\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    # Setup callbacks\n",
    "    history = AccLossHistory()\n",
    "\n",
    "    if isEarlyStopping:\n",
    "        earlyStopping = EarlyStopping(monitor='val_acc', min_delta=0.001, patience=n_patience, verbose=1, mode='auto')\n",
    "        callbacks = [history, earlyStopping]\n",
    "    else:\n",
    "        callbacks = [history]\n",
    "\n",
    "    # Model fit\n",
    "    fit_hist = model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=n_epoch,\n",
    "          verbose=1,\n",
    "          validation_split=0.25,\n",
    "          callbacks=callbacks,\n",
    "          shuffle=True)\n",
    "\n",
    "    # Record metrics\n",
    "    history_list.append(history)\n",
    "    \n",
    "    #Save model\n",
    "    docs_dir=os.path.expanduser('~/SSVEP_CNN/Results/Models/')\n",
    "    model.save_weights(os.path.join(docs_dir, 'model_%d'%subject))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = process_data(SSVEP_l, SSVEP_label, n_class=2, day_index=train_day, subject_index=1)\n",
    "print(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conv1_size_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-853dc96d46a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1_size_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv2_size_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_acc4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_loss4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_acc4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'conv1_size_list' is not defined"
     ]
    }
   ],
   "source": [
    "x4 = len(conv1_size_list)\n",
    "y4 = len(conv2_size_list)\n",
    "test_acc4 = np.empty((x4, y4))\n",
    "test_loss4 = np.empty((x4, y4))\n",
    "val_acc4 = np.empty((x4, y4))\n",
    "val_loss4 = np.empty((x4, y4))\n",
    "\n",
    "for i in range(x4):\n",
    "    for j in range(y4):\n",
    "        test_acc4[i][j] = score_list4[i][j][-1]\n",
    "        test_loss4[i][j] = score_list4[i][j][0]\n",
    "        val_acc4[i][j] = history_list4[i][j].acc[-1][-1]\n",
    "        val_loss4[i][j] = history_list4[i][j].loss[-1][0]\n",
    "        \n",
    "scores4 = np.array(score_list4)\n",
    "histories4 = np.array(history_list4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs_dir=os.path.expanduser('~/SSVEP_CNN/Results')\n",
    "np.save(os.path.join(docs_dir, 'ConvSize_3x1_test_acc'), test_acc4)\n",
    "np.save(os.path.join(docs_dir, 'ConvSize_3x1_val_acc'), val_acc4)\n",
    "np.save(os.path.join(docs_dir, 'ConvSize_3x1_val_loss'), val_loss4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def heatmap(data, row_labels, col_labels, ax=None,\n",
    "            cbar_kw={}, cbarlabel=\"\", **kwargs):\n",
    "    \"\"\"\n",
    "    Create a heatmap from a numpy array and two lists of labels.\n",
    "\n",
    "    Arguments:\n",
    "        data       : A 2D numpy array of shape (N,M)\n",
    "        row_labels : A list or array of length N with the labels\n",
    "                     for the rows\n",
    "        col_labels : A list or array of length M with the labels\n",
    "                     for the columns\n",
    "    Optional arguments:\n",
    "        ax         : A matplotlib.axes.Axes instance to which the heatmap\n",
    "                     is plotted. If not provided, use current axes or\n",
    "                     create a new one.\n",
    "        cbar_kw    : A dictionary with arguments to\n",
    "                     :meth:`matplotlib.Figure.colorbar`.\n",
    "        cbarlabel  : The label for the colorbar\n",
    "    All other arguments are directly passed on to the imshow call.\n",
    "    \"\"\"\n",
    "\n",
    "    if not ax:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    # Plot the heatmap\n",
    "    im = ax.imshow(data, **kwargs)\n",
    "\n",
    "    # Create colorbar\n",
    "    cbar = ax.figure.colorbar(im, ax=ax, **cbar_kw)\n",
    "    cbar.ax.set_ylabel(cbarlabel, rotation=-90, va=\"bottom\")\n",
    "\n",
    "    # We want to show all ticks...\n",
    "    ax.set_xticks(np.arange(data.shape[1]))\n",
    "    ax.set_yticks(np.arange(data.shape[0]))\n",
    "    # ... and label them with the respective list entries.\n",
    "    ax.set_xticklabels(col_labels)\n",
    "    ax.set_yticklabels(row_labels)\n",
    "\n",
    "    # Let the horizontal axes labeling appear on top.\n",
    "    ax.tick_params(top=False, bottom=True,\n",
    "                   labeltop=False, labelbottom=True)\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=0, ha=\"center\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Turn spines off and create white grid.\n",
    "    for edge, spine in ax.spines.items():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    ax.set_xticks(np.arange(data.shape[1]+1)-.5, minor=True)\n",
    "    ax.set_yticks(np.arange(data.shape[0]+1)-.5, minor=True)\n",
    "    ax.grid(which=\"minor\", color=\"w\", linestyle='-', linewidth=3)\n",
    "    ax.tick_params(which=\"minor\", bottom=False, left=False)\n",
    "\n",
    "    return im, cbar\n",
    "\n",
    "\n",
    "def annotate_heatmap(im, data=None, valfmt=\"{x:.2f}\",\n",
    "                     textcolors=[\"black\", \"white\"],\n",
    "                     threshold=None, **textkw):\n",
    "    \"\"\"\n",
    "    A function to annotate a heatmap.\n",
    "\n",
    "    Arguments:\n",
    "        im         : The AxesImage to be labeled.\n",
    "    Optional arguments:\n",
    "        data       : Data used to annotate. If None, the image's data is used.\n",
    "        valfmt     : The format of the annotations inside the heatmap.\n",
    "                     This should either use the string format method, e.g.\n",
    "                     \"$ {x:.2f}\", or be a :class:`matplotlib.ticker.Formatter`.\n",
    "        textcolors : A list or array of two color specifications. The first is\n",
    "                     used for values below a threshold, the second for those\n",
    "                     above.\n",
    "        threshold  : Value in data units according to which the colors from\n",
    "                     textcolors are applied. If None (the default) uses the\n",
    "                     middle of the colormap as separation.\n",
    "\n",
    "    Further arguments are passed on to the created text labels.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(data, (list, np.ndarray)):\n",
    "        data = im.get_array()\n",
    "\n",
    "    # Normalize the threshold to the images color range.\n",
    "    if threshold is not None:\n",
    "        threshold = im.norm(threshold)\n",
    "    else:\n",
    "        threshold = im.norm(data.max())/2.\n",
    "\n",
    "    # Set default alignment to center, but allow it to be\n",
    "    # overwritten by textkw.\n",
    "    kw = dict(horizontalalignment=\"center\",\n",
    "              verticalalignment=\"center\")\n",
    "    kw.update(textkw)\n",
    "\n",
    "    # Get the formatter in case a string is supplied\n",
    "    if isinstance(valfmt, str):\n",
    "        valfmt = matplotlib.ticker.StrMethodFormatter(valfmt)\n",
    "\n",
    "    # Loop over the data and create a `Text` for each \"pixel\".\n",
    "    # Change the text's color depending on the data.\n",
    "    texts = []\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            kw.update(color=textcolors[im.norm(data[i, j]) > threshold])\n",
    "            text = im.axes.text(j, i, valfmt(data[i, j], None), **kw)\n",
    "            texts.append(text)\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''PLOTING MODULE'''\n",
    "fig = plt.figure(figsize=(13,5))\n",
    "\n",
    "val_plot = fig.add_subplot(121)\n",
    "# val_plot.imshow(val_acc, interpolation='nearest')\n",
    "# plt.legend(loc=4, borderaxespad=0.7)\n",
    "# plt.title('Validation Accuracy Graph')\n",
    "# plt.ylabel('Conv1 Size')\n",
    "# plt.xlabel('Conv2 Size')\n",
    "# plt.yticks(range(len(conv1_size_list)), conv1_size_list)\n",
    "# plt.xticks(range(len(conv2_size_list)), conv2_size_list)\n",
    "\n",
    "val_im, cbar = heatmap(val_acc4, conv1_size_list, conv2_size_list, ax=val_plot,\n",
    "                   cmap='magma_r', cbarlabel=\"Accuracy\")\n",
    "texts = annotate_heatmap(val_im, valfmt=\"{x:.3f}\")\n",
    "\n",
    "plt.title('Validation Accuracy Graph')\n",
    "plt.ylabel('Conv1 Size')\n",
    "plt.xlabel('Conv2 Size')\n",
    "\n",
    "test_plot = fig.add_subplot(122)\n",
    "# test_plot.imshow(test_acc, interpolation='nearest')\n",
    "# # plt.legend(loc=1, borderaxespad=0.7)\n",
    "# plt.title('Test Accuracy Graph')\n",
    "# plt.ylabel('Conv1 Size')\n",
    "# plt.xlabel('Conv2 Size')\n",
    "# plt.yticks(range(len(conv1_size_list)), conv1_size_list)\n",
    "# plt.xticks(range(len(conv2_size_list)), conv2_size_list)\n",
    "\n",
    "test_im, cbar = heatmap(test_acc4, conv1_size_list, conv2_size_list, ax=test_plot,\n",
    "                   cmap='magma_r', cbarlabel=\"Accuracy\")\n",
    "texts = annotate_heatmap(test_im, valfmt=\"{x:.3f}\")\n",
    "\n",
    "plt.title('Test Accuracy Graph')\n",
    "plt.ylabel('Conv1 Size')\n",
    "plt.xlabel('Conv2 Size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "So far, the best convolutional layer configuration is\n",
    "Conv1: No. of filters = 5, Filter Size = (1, 25)\n",
    "Conv2: No. of filters = 10, Filter Size = (9, 1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "acc_plot = fig.add_subplot(121)\n",
    "for i in range(len(conv1_size_list)):\n",
    "    his = history_list[i]\n",
    "    acc_plot.plot(np.array(his.acc)[:,1], label='Conv1 Size {}'.format(conv1_size_list[i]))\n",
    "plt.legend(loc=4, borderaxespad=0.7)\n",
    "plt.title('Validation Accuracy Graph')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of Epochs')\n",
    "\n",
    "loss_plot = fig.add_subplot(122)\n",
    "for i in range(len(conv1_size_list)):\n",
    "    his = history_list[i]\n",
    "    loss_plot.plot(np.array(his.loss)[:,1], label='Conv1 Size {}'.format(conv1_size_list[i]))\n",
    "plt.legend(loc=1, borderaxespad=0.7)\n",
    "plt.title('Validation Loss Graph')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Number of Epochs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = np.array(score_list)\n",
    "t = range(len(conv1_size_list))\n",
    "\n",
    "fig, acc_axis = plt.subplots()\n",
    "\n",
    "color = 'tab:red'\n",
    "acc_axis.set_ylabel('Accuracy', color=color)\n",
    "acc_axis.plot(t, scores[:,1], 'x--', color=color)\n",
    "acc_axis.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "loss_axis = acc_axis.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "loss_axis.set_ylabel('Loss', color=color)  # we already handled the x-label with ax1\n",
    "loss_axis.plot(t, scores[:,0], 'o--', color=color)\n",
    "loss_axis.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "plt.title('Test Result')\n",
    "plt.xlabel('Conv1 Size')\n",
    "plt.xticks(t, conv1_size_list)\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
