{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3636180585040203710\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io as io\n",
    "import os\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Input, Flatten\n",
    "import keras.backend as K\n",
    "from keras.constraints import max_norm\n",
    "from keras.regularizers import l1_l2\n",
    "from keras.layers.core import Dense, Activation, Dropout, Permute, Reshape\n",
    "from keras.callbacks import Callback, EarlyStopping\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "def square(x):\n",
    "    return K.square(x)\n",
    "\n",
    "def log(x):\n",
    "    return K.log(K.clip(x, min_value = 1e-7, max_value = 10000))   \n",
    "\n",
    "def safe_log(x):\n",
    "    return K.log(x + 1e-7)\n",
    "\n",
    "def process_data(train, label, n_class=2, day_index=1, subject_index=1, shuffle=True):\n",
    "    train = np.squeeze(train[:,:,np.where(label[:,1]==day_index)])\n",
    "    train = np.transpose(train, axes=[2,0,1])\n",
    "    train = train.reshape(train.shape[0], 1, train.shape[1], train.shape[2])\n",
    "    \n",
    "    label = np.squeeze(label[np.where(label[:,1]==day_index),0])   \n",
    "    if n_class == 2:\n",
    "        label[np.where(label != subject_index)] = subject_index + 1\n",
    "        label = keras.utils.to_categorical(label-subject_index, n_class)\n",
    "    else:\n",
    "        label = keras.utils.to_categorical(label-1, n_class)\n",
    "        \n",
    "    if shuffle:\n",
    "        permutation = np.random.permutation(train.shape[0])\n",
    "        train = train[permutation,:,:]\n",
    "        label = label[permutation,:]\n",
    "        \n",
    "    return train, label "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Keras implementation of the Shallow Convolutional Network as described\n",
    "    in Schirrmeister et. al. (2017), arXiv 1703.0505\n",
    "    \n",
    "    Assumes the input is a 2-second EEG signal sampled at 128Hz. Note that in \n",
    "    the original paper, they do temporal convolutions of length 25 for EEG\n",
    "    data sampled at 250Hz. We instead use length 13 since the sampling rate is \n",
    "    roughly half of the 250Hz which the paper used. The pool_size and stride\n",
    "    in later layers is also approximately half of what is used in the paper.\n",
    "    \n",
    "                     ours        original paper\n",
    "    pool_size        1, 35       1, 75\n",
    "    strides          1, 7        1, 15\n",
    "    conv filters     1, 13       1, 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ShallowConvNet(input_shape, n_class=2, conv1_size=(1, 25), conv2_size=(9, 1), conv1_filter=5, conv2_filter=20):\n",
    "    dropout_rate = 0.5\n",
    "    \n",
    "    # start the model\n",
    "    input_EEG = Input(input_shape)\n",
    "    block1       = Conv2D(conv1_filter, conv1_size, kernel_constraint = max_norm(2.))(input_EEG)\n",
    "    block1       = Conv2D(conv2_filter, conv2_size, use_bias=True, kernel_constraint = max_norm(2.))(block1)\n",
    "    block1       = BatchNormalization(axis=1, epsilon=1e-05, momentum=0.1)(block1)\n",
    "    block1       = Activation(square)(block1)\n",
    "    block1       = AveragePooling2D(pool_size=(1, 30), strides=(1, 10))(block1)\n",
    "    block1       = Activation(safe_log)(block1)\n",
    "    block1       = Dropout(dropout_rate)(block1)\n",
    "    flatten      = Flatten()(block1)\n",
    "    dense        = Dense(n_class, kernel_constraint = max_norm(0.5))(flatten)\n",
    "    softmax      = Activation('softmax')(dense)\n",
    "    \n",
    "    return Model(inputs=input_EEG, outputs=softmax)\n",
    "\n",
    "class AccLossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.acc = []\n",
    "        self.loss = []\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.acc.append([logs.get('acc'), logs.get('val_acc')])\n",
    "        self.loss.append([logs.get('loss'), logs.get('val_loss')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datapath = '/Users/dustintt123/SSVEP_CNN/SSVEP_Data/'\n",
    "SSVEP_l = io.loadmat(datapath+'SSVEP_l.mat')['SSVEP_l']\n",
    "SSVEP_h = io.loadmat(datapath+'SSVEP_h.mat')['SSVEP_h']\n",
    "SSVEP_label = io.loadmat(datapath+'SSVEP_label.mat')['label'] # i_subj, i_session, i_stim, i_trial\n",
    "\n",
    "# binary one-vs-all classification\n",
    "batch_size = 100\n",
    "n_epoch = 150\n",
    "isEarlyStopping = True\n",
    "n_patience = 10\n",
    "\n",
    "history_list = []\n",
    "yhat_list = []\n",
    "score_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 1, 9, 247)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 5, 9, 223)         130       \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 20, 1, 223)        920       \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 20, 1, 223)        80        \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 20, 1, 223)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_9 (Average (None, 20, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 20, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 20, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 802       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 1,932\n",
      "Trainable params: 1,892\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'zmq.backend.cython.message.Frame.__dealloc__'\n",
      "Traceback (most recent call last):\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 12, in zmq.backend.cython.checkrc._check_rc (zmq/backend/cython/message.c:4294)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1440 samples, validate on 480 samples\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-6e4a7c1729d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m           \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m           \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m           shuffle=True)\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Record metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2633\u001b[0m                                 \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2635\u001b[0;31m                                 session)\n\u001b[0m\u001b[1;32m   2636\u001b[0m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_make_callable\u001b[0;34m(self, feed_arrays, feed_symbols, symbol_vals, session)\u001b[0m\n\u001b[1;32m   2585\u001b[0m         \u001b[0mcallable_opts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2586\u001b[0m         \u001b[0;31m# Create callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2587\u001b[0;31m         \u001b[0mcallable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable_from_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallable_opts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2588\u001b[0m         \u001b[0;31m# Cache parameters corresponding to the generated callable, so that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2589\u001b[0m         \u001b[0;31m# we can detect future mismatches and refresh the callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_make_callable_from_options\u001b[0;34m(self, callable_options)\u001b[0m\n\u001b[1;32m   1481\u001b[0m     \"\"\"\n\u001b[1;32m   1482\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1483\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mBaseSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallable_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session, callable_options)\u001b[0m\n\u001b[1;32m   1436\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1437\u001b[0m             self._handle = tf_session.TF_SessionMakeCallable(\n\u001b[0;32m-> 1438\u001b[0;31m                 session._session, options_ptr, status)\n\u001b[0m\u001b[1;32m   1439\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m             self._handle = tf_session.TF_DeprecatedSessionMakeCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    subject = i+1\n",
    "\n",
    "    x_train, y_train = process_data(SSVEP_l, SSVEP_label, n_class=2, day_index=1, subject_index=subject)\n",
    "    x_test, y_test = process_data(SSVEP_l, SSVEP_label, n_class=2, day_index=2, subject_index=subject)\n",
    "    n_trial, n_height, n_channel, n_timestamp = x_train.shape\n",
    "\n",
    "    # Setup model\n",
    "    model = ShallowConvNet(x_train.shape[1:])\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    # Setup callbacks\n",
    "    history = AccLossHistory()\n",
    "\n",
    "    if isEarlyStopping:\n",
    "        earlyStopping = EarlyStopping(monitor='val_acc', min_delta=0.001, patience=n_patience, verbose=1, mode='auto')\n",
    "        callbacks = [history, earlyStopping]\n",
    "    else:\n",
    "        callbacks = [history]\n",
    "\n",
    "    # Model fit\n",
    "    fit_hist = model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=n_epoch,\n",
    "          verbose=1,\n",
    "          validation_split=0.25,\n",
    "          callbacks=callbacks,\n",
    "          shuffle=True)\n",
    "\n",
    "    # Record metrics\n",
    "    y_hat = model.predict_on_batch(x_test)\n",
    "    score = model.evaluate(x_test, y_test, verbose = 1)\n",
    "    history_list.append(history)\n",
    "    score_list.append(score)\n",
    "    yhat_list.append(y_hat)\n",
    "    \n",
    "    #Save model\n",
    "    docs_dir=os.path.expanduser('~/SSVEP_CNN/Results/Models/')\n",
    "    model.save_weights(os.path.join(docs_dir, 'model_%d'%subject))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conv1_size_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-853dc96d46a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1_size_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv2_size_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_acc4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_loss4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_acc4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'conv1_size_list' is not defined"
     ]
    }
   ],
   "source": [
    "x4 = len(conv1_size_list)\n",
    "y4 = len(conv2_size_list)\n",
    "test_acc4 = np.empty((x4, y4))\n",
    "test_loss4 = np.empty((x4, y4))\n",
    "val_acc4 = np.empty((x4, y4))\n",
    "val_loss4 = np.empty((x4, y4))\n",
    "\n",
    "for i in range(x4):\n",
    "    for j in range(y4):\n",
    "        test_acc4[i][j] = score_list4[i][j][-1]\n",
    "        test_loss4[i][j] = score_list4[i][j][0]\n",
    "        val_acc4[i][j] = history_list4[i][j].acc[-1][-1]\n",
    "        val_loss4[i][j] = history_list4[i][j].loss[-1][0]\n",
    "        \n",
    "scores4 = np.array(score_list4)\n",
    "histories4 = np.array(history_list4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs_dir=os.path.expanduser('~/SSVEP_CNN/Results')\n",
    "np.save(os.path.join(docs_dir, 'ConvSize_3x1_test_acc'), test_acc4)\n",
    "np.save(os.path.join(docs_dir, 'ConvSize_3x1_val_acc'), val_acc4)\n",
    "np.save(os.path.join(docs_dir, 'ConvSize_3x1_val_loss'), val_loss4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def heatmap(data, row_labels, col_labels, ax=None,\n",
    "            cbar_kw={}, cbarlabel=\"\", **kwargs):\n",
    "    \"\"\"\n",
    "    Create a heatmap from a numpy array and two lists of labels.\n",
    "\n",
    "    Arguments:\n",
    "        data       : A 2D numpy array of shape (N,M)\n",
    "        row_labels : A list or array of length N with the labels\n",
    "                     for the rows\n",
    "        col_labels : A list or array of length M with the labels\n",
    "                     for the columns\n",
    "    Optional arguments:\n",
    "        ax         : A matplotlib.axes.Axes instance to which the heatmap\n",
    "                     is plotted. If not provided, use current axes or\n",
    "                     create a new one.\n",
    "        cbar_kw    : A dictionary with arguments to\n",
    "                     :meth:`matplotlib.Figure.colorbar`.\n",
    "        cbarlabel  : The label for the colorbar\n",
    "    All other arguments are directly passed on to the imshow call.\n",
    "    \"\"\"\n",
    "\n",
    "    if not ax:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    # Plot the heatmap\n",
    "    im = ax.imshow(data, **kwargs)\n",
    "\n",
    "    # Create colorbar\n",
    "    cbar = ax.figure.colorbar(im, ax=ax, **cbar_kw)\n",
    "    cbar.ax.set_ylabel(cbarlabel, rotation=-90, va=\"bottom\")\n",
    "\n",
    "    # We want to show all ticks...\n",
    "    ax.set_xticks(np.arange(data.shape[1]))\n",
    "    ax.set_yticks(np.arange(data.shape[0]))\n",
    "    # ... and label them with the respective list entries.\n",
    "    ax.set_xticklabels(col_labels)\n",
    "    ax.set_yticklabels(row_labels)\n",
    "\n",
    "    # Let the horizontal axes labeling appear on top.\n",
    "    ax.tick_params(top=False, bottom=True,\n",
    "                   labeltop=False, labelbottom=True)\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=0, ha=\"center\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Turn spines off and create white grid.\n",
    "    for edge, spine in ax.spines.items():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    ax.set_xticks(np.arange(data.shape[1]+1)-.5, minor=True)\n",
    "    ax.set_yticks(np.arange(data.shape[0]+1)-.5, minor=True)\n",
    "    ax.grid(which=\"minor\", color=\"w\", linestyle='-', linewidth=3)\n",
    "    ax.tick_params(which=\"minor\", bottom=False, left=False)\n",
    "\n",
    "    return im, cbar\n",
    "\n",
    "\n",
    "def annotate_heatmap(im, data=None, valfmt=\"{x:.2f}\",\n",
    "                     textcolors=[\"black\", \"white\"],\n",
    "                     threshold=None, **textkw):\n",
    "    \"\"\"\n",
    "    A function to annotate a heatmap.\n",
    "\n",
    "    Arguments:\n",
    "        im         : The AxesImage to be labeled.\n",
    "    Optional arguments:\n",
    "        data       : Data used to annotate. If None, the image's data is used.\n",
    "        valfmt     : The format of the annotations inside the heatmap.\n",
    "                     This should either use the string format method, e.g.\n",
    "                     \"$ {x:.2f}\", or be a :class:`matplotlib.ticker.Formatter`.\n",
    "        textcolors : A list or array of two color specifications. The first is\n",
    "                     used for values below a threshold, the second for those\n",
    "                     above.\n",
    "        threshold  : Value in data units according to which the colors from\n",
    "                     textcolors are applied. If None (the default) uses the\n",
    "                     middle of the colormap as separation.\n",
    "\n",
    "    Further arguments are passed on to the created text labels.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(data, (list, np.ndarray)):\n",
    "        data = im.get_array()\n",
    "\n",
    "    # Normalize the threshold to the images color range.\n",
    "    if threshold is not None:\n",
    "        threshold = im.norm(threshold)\n",
    "    else:\n",
    "        threshold = im.norm(data.max())/2.\n",
    "\n",
    "    # Set default alignment to center, but allow it to be\n",
    "    # overwritten by textkw.\n",
    "    kw = dict(horizontalalignment=\"center\",\n",
    "              verticalalignment=\"center\")\n",
    "    kw.update(textkw)\n",
    "\n",
    "    # Get the formatter in case a string is supplied\n",
    "    if isinstance(valfmt, str):\n",
    "        valfmt = matplotlib.ticker.StrMethodFormatter(valfmt)\n",
    "\n",
    "    # Loop over the data and create a `Text` for each \"pixel\".\n",
    "    # Change the text's color depending on the data.\n",
    "    texts = []\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            kw.update(color=textcolors[im.norm(data[i, j]) > threshold])\n",
    "            text = im.axes.text(j, i, valfmt(data[i, j], None), **kw)\n",
    "            texts.append(text)\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''PLOTING MODULE'''\n",
    "fig = plt.figure(figsize=(13,5))\n",
    "\n",
    "val_plot = fig.add_subplot(121)\n",
    "# val_plot.imshow(val_acc, interpolation='nearest')\n",
    "# plt.legend(loc=4, borderaxespad=0.7)\n",
    "# plt.title('Validation Accuracy Graph')\n",
    "# plt.ylabel('Conv1 Size')\n",
    "# plt.xlabel('Conv2 Size')\n",
    "# plt.yticks(range(len(conv1_size_list)), conv1_size_list)\n",
    "# plt.xticks(range(len(conv2_size_list)), conv2_size_list)\n",
    "\n",
    "val_im, cbar = heatmap(val_acc4, conv1_size_list, conv2_size_list, ax=val_plot,\n",
    "                   cmap='magma_r', cbarlabel=\"Accuracy\")\n",
    "texts = annotate_heatmap(val_im, valfmt=\"{x:.3f}\")\n",
    "\n",
    "plt.title('Validation Accuracy Graph')\n",
    "plt.ylabel('Conv1 Size')\n",
    "plt.xlabel('Conv2 Size')\n",
    "\n",
    "test_plot = fig.add_subplot(122)\n",
    "# test_plot.imshow(test_acc, interpolation='nearest')\n",
    "# # plt.legend(loc=1, borderaxespad=0.7)\n",
    "# plt.title('Test Accuracy Graph')\n",
    "# plt.ylabel('Conv1 Size')\n",
    "# plt.xlabel('Conv2 Size')\n",
    "# plt.yticks(range(len(conv1_size_list)), conv1_size_list)\n",
    "# plt.xticks(range(len(conv2_size_list)), conv2_size_list)\n",
    "\n",
    "test_im, cbar = heatmap(test_acc4, conv1_size_list, conv2_size_list, ax=test_plot,\n",
    "                   cmap='magma_r', cbarlabel=\"Accuracy\")\n",
    "texts = annotate_heatmap(test_im, valfmt=\"{x:.3f}\")\n",
    "\n",
    "plt.title('Test Accuracy Graph')\n",
    "plt.ylabel('Conv1 Size')\n",
    "plt.xlabel('Conv2 Size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "So far, the best convolutional layer configuration is\n",
    "Conv1: No. of filters = 5, Filter Size = (1, 25)\n",
    "Conv2: No. of filters = 10, Filter Size = (9, 1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "acc_plot = fig.add_subplot(121)\n",
    "for i in range(len(conv1_size_list)):\n",
    "    his = history_list[i]\n",
    "    acc_plot.plot(np.array(his.acc)[:,1], label='Conv1 Size {}'.format(conv1_size_list[i]))\n",
    "plt.legend(loc=4, borderaxespad=0.7)\n",
    "plt.title('Validation Accuracy Graph')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of Epochs')\n",
    "\n",
    "loss_plot = fig.add_subplot(122)\n",
    "for i in range(len(conv1_size_list)):\n",
    "    his = history_list[i]\n",
    "    loss_plot.plot(np.array(his.loss)[:,1], label='Conv1 Size {}'.format(conv1_size_list[i]))\n",
    "plt.legend(loc=1, borderaxespad=0.7)\n",
    "plt.title('Validation Loss Graph')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Number of Epochs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = np.array(score_list)\n",
    "t = range(len(conv1_size_list))\n",
    "\n",
    "fig, acc_axis = plt.subplots()\n",
    "\n",
    "color = 'tab:red'\n",
    "acc_axis.set_ylabel('Accuracy', color=color)\n",
    "acc_axis.plot(t, scores[:,1], 'x--', color=color)\n",
    "acc_axis.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "loss_axis = acc_axis.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "loss_axis.set_ylabel('Loss', color=color)  # we already handled the x-label with ax1\n",
    "loss_axis.plot(t, scores[:,0], 'o--', color=color)\n",
    "loss_axis.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "plt.title('Test Result')\n",
    "plt.xlabel('Conv1 Size')\n",
    "plt.xticks(t, conv1_size_list)\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
